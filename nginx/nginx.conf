# Main nginx configuration for ML Inference Server
# This file configures nginx as a reverse proxy and load balancer

# Worker processes - usually set to number of CPU cores
worker_processes auto;

# Maximum number of connections per worker
events {
    worker_connections 1024;
    use epoll;                    # Efficient connection handling on Linux
    multi_accept on;              # Accept multiple connections at once
}

http {
    # ==============================================================================
    # Basic HTTP Configuration
    # ==============================================================================
    
    # MIME types
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    
    # Logging format with timing information
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';
    
    # Log files
    access_log /var/log/nginx/access.log main;
    error_log  /var/log/nginx/error.log warn;
    
    # ==============================================================================
    # Performance Optimizations
    # ==============================================================================
    
    # Efficient file serving
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    
    # Timeout configurations
    keepalive_timeout 65;
    client_max_body_size 10M;      # Max request size (for large text inputs)
    client_body_timeout 60s;       # Client body read timeout
    client_header_timeout 60s;     # Client header read timeout
    
    # Compression for text responses
    gzip on;
    gzip_vary on;
    gzip_min_length 1000;
    gzip_types
        application/json
        application/javascript
        text/css
        text/javascript
        text/plain
        text/xml;
    
    # ==============================================================================
    # Upstream Backend Configuration (Load Balancing)
    # ==============================================================================
    
    upstream ml_backend {
        # Load balancing method - can be round_robin, least_conn, ip_hash
        least_conn;                 # Route to server with fewest active connections
        
        # Backend servers (our FastAPI workers)
        server app:8000 max_fails=3 fail_timeout=30s;
        
        # Health checks
        keepalive 32;               # Keep connections alive to backends
    }
    
    # ==============================================================================
    # Rate Limiting (Production Security)
    # ==============================================================================
    
    # Define rate limiting zones
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=health_limit:1m rate=30r/s;
    
    # ==============================================================================
    # Server Configuration
    # ==============================================================================
    
    # Include additional server configurations
    include /etc/nginx/conf.d/*.conf;
}