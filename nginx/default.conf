# Default server configuration for ML Inference API
# This handles incoming HTTP requests and routes them to FastAPI backends

server {
    # ==============================================================================
    # Basic Server Configuration
    # ==============================================================================
    
    listen 80;
    server_name localhost;
    
    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    
    # ==============================================================================
    # API Routes (Main Application)
    # ==============================================================================
    
    # All API endpoints
    location / {
        # Rate limiting
        limit_req zone=api_limit burst=20 nodelay;
        
        # Proxy headers
        proxy_pass http://ml_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Timeouts for ML inference
        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 120s;        # Allow time for model inference
        
        # Buffer settings
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
        
        # Handle WebSocket upgrades (if needed in future)
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
    
    # ==============================================================================
    # Health Check Routes (Special Handling)
    # ==============================================================================
    
    # Health checks with relaxed rate limiting
    location /health {
        limit_req zone=health_limit burst=10 nodelay;
        
        proxy_pass http://ml_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Faster timeouts for health checks
        proxy_connect_timeout 5s;
        proxy_send_timeout 10s;
        proxy_read_timeout 10s;
        
        # Add health check headers
        add_header X-Health-Check "nginx-proxy" always;
    }
    
    # ==============================================================================
    # API Documentation Routes
    # ==============================================================================
    
    # Swagger UI and ReDoc
    location ~ ^/(docs|redoc|openapi.json) {
        limit_req zone=api_limit burst=5 nodelay;
        
        proxy_pass http://ml_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Cache documentation pages
        proxy_cache_valid 200 1h;
        add_header X-Cache-Status $upstream_cache_status;
    }
    
    # ==============================================================================
    # Text Generation Route (Special Configuration)
    # ==============================================================================
    
    # Text generation endpoint with extended timeouts
    location /generate {
        limit_req zone=api_limit burst=10 nodelay;
        
        proxy_pass http://ml_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Extended timeouts for ML inference
        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 180s;        # 3 minutes for complex generation
        
        # Larger buffer for potentially large responses
        proxy_buffer_size 8k;
        proxy_buffers 16 8k;
        
        # Add generation-specific headers
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-Generation-Service "ml-inference-api" always;
    }
    
    # ==============================================================================
    # Error Pages and Monitoring
    # ==============================================================================
    
    # Custom error pages
    error_page 502 503 504 /50x.html;
    location = /50x.html {
        root /usr/share/nginx/html;
        internal;
    }
    
    # Nginx status page (for monitoring)
    location /nginx-status {
        stub_status on;
        access_log off;
        allow 127.0.0.1;            # Only allow local access
        deny all;
    }
    
    # Block access to hidden files
    location ~ /\. {
        deny all;
        access_log off;
        log_not_found off;
    }
}